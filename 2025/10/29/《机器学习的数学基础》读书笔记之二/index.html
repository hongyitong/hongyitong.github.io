<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hongyitong.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.11.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

<meta name="robots" content="noindex,follow">

    <meta name="description" content="2、线性代数 Linear Algebra 在形式化一些直观概念时，常见的方法是构造一组对象(符号)和一些操作这些对象的规则。 这就是所谓的代数(algebra)。线性代数是研究向量以及使用某些确定的规则来操作向量的 一门学科。 我们许多人从学校里知道的向量被称为“几何向量”，通常用上方带一个小箭头的字母表示。  向量是特殊的对象，将它们相加并乘以标量产生的是另一个相同类型的对象。从抽象的数学来看">
<meta property="og:type" content="article">
<meta property="og:title" content="《机器学习的数学基础》（2&#x2F;7）">
<meta property="og:url" content="http://hongyitong.github.io/2025/10/29/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BA%8C/index.html">
<meta property="og:site_name" content="心情驿站">
<meta property="og:description" content="2、线性代数 Linear Algebra 在形式化一些直观概念时，常见的方法是构造一组对象(符号)和一些操作这些对象的规则。 这就是所谓的代数(algebra)。线性代数是研究向量以及使用某些确定的规则来操作向量的 一门学科。 我们许多人从学校里知道的向量被称为“几何向量”，通常用上方带一个小箭头的字母表示。  向量是特殊的对象，将它们相加并乘以标量产生的是另一个相同类型的对象。从抽象的数学来看">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://hongyitong.github.io/img3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80Part1/%E5%8F%98%E6%8D%A2.png">
<meta property="og:image" content="http://hongyitong.github.io/img3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80Part1/F2.12.png">
<meta property="article:published_time" content="2025-10-28T16:00:00.000Z">
<meta property="article:modified_time" content="2025-12-12T06:40:15.298Z">
<meta property="article:author" content="Rayman.hung">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://hongyitong.github.io/img3/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80Part1/%E5%8F%98%E6%8D%A2.png">


<link rel="canonical" href="http://hongyitong.github.io/2025/10/29/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BA%8C/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://hongyitong.github.io/2025/10/29/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BA%8C/","path":"2025/10/29/《机器学习的数学基础》读书笔记之二/","title":"《机器学习的数学基础》（2/7）"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>《机器学习的数学基础》（2/7） | 心情驿站</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZXGEJDXQ33"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-ZXGEJDXQ33","only_pageview":false}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?ff358b9c7e949787b074bfc9c8019a9d"></script>




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">心情驿站</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Rayman</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section">首页</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section">分类</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section">关于</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section">归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0"><span class="nav-text">2、线性代数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E6%B1%82%E8%A7%A3"><span class="nav-text">2.1 线性方程求解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BE%A4"><span class="nav-text">2.2 群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="nav-text">2.3 线性变换的定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%98%E6%8D%A2%E7%9F%A9%E9%98%B5"><span class="nav-text">2.4 变换矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B8%E4%BC%BC%E7%9F%A9%E9%98%B5"><span class="nav-text">2.5 相似矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%81%92%E7%AD%89%E6%98%A0%E5%B0%84"><span class="nav-text">2.6 恒等映射</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E5%8F%98%E6%8D%A2"><span class="nav-text">2.7 基变换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%98%E9%87%8F%E5%8F%98%E6%8D%A2%E5%92%8C%E5%9F%BA%E5%8F%98%E6%8D%A2%E5%8C%BA%E5%88%AB"><span class="nav-text">2.8 变量变换和基变换区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%83%8F%E4%B8%8E%E6%A0%B8"><span class="nav-text">2.8 像与核</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%BF%E5%B0%84%E7%A9%BA%E9%97%B4"><span class="nav-text">2.9 仿射空间</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%BF%E5%B0%84%E6%98%A0%E5%B0%84"><span class="nav-text">2.10 仿射映射</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Rayman.hung</p>
  <div class="site-description" itemprop="description">技术分享、读书心得、心情记录</div>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://hongyitong.github.io/2025/10/29/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BA%8C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Rayman.hung">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="心情驿站">
      <meta itemprop="description" content="技术分享、读书心得、心情记录">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="《机器学习的数学基础》（2/7） | 心情驿站">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          《机器学习的数学基础》（2/7）
        </h1>

        </h1>
          
             <p class="post-subtitle">读书笔记之二：线性代数</p>
          
        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-10-29 00:00:00" itemprop="dateCreated datePublished" datetime="2025-10-29T00:00:00+08:00">2025-10-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AF%BB%E4%B9%A6%E5%BF%83%E5%BE%97%EF%BC%88%E8%87%AA%E7%84%B6%E7%A7%91%E5%AD%A6%EF%BC%89/" itemprop="url" rel="index"><span itemprop="name">读书心得（自然科学）</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="线性代数">2、线性代数</h2>
<p>Linear Algebra</p>
<p>在形式化一些直观概念时，常见的方法是构造一组对象(符号)和一些操作这些对象的规则。
这就是所谓的代数(algebra)。线性代数是研究向量以及使用某些确定的规则来操作向量的
一门学科。
我们许多人从学校里知道的向量被称为“几何向量”，通常用上方带一个小箭头的字母表示。</p>
<blockquote>
<p>向量是特殊的对象，将它们<strong><u>相加并乘以</u></strong>标量产生的是另一个相同类型的对象。从抽象的数学来看，任何满足这两个性质的物体都可以被认为是向量。</p>
</blockquote>
<span id="more"></span>
<h3 id="线性方程求解">2.1 线性方程求解</h3>
<p>出于数值精度的原因，通常不建议计算逆或伪逆。因此，在下文中，我们将简要讨论求解线性方程组的其他方法。</p>
<p><strong><u>高斯消元法</u></strong>在计算行列式、检查向量集是否线性独立、计算矩阵的逆，计算矩阵的秩，和确定向量空间的基时起着重要作用。高斯消元法是一种直观而有建设性的方法来解决一个含成千上万变量的线性方程组。然而，对于具有数百万个变量的方程组，这是不切实际的，因为所需的运算量是按联立方程组的数量的立方增长的。</p>
<p>在实践中，许多线性方程组都是通过定<strong><u>常迭代方法</u></strong>(stationary
iterative
methods)间接求解的，如Richardson方法、Jacobi方法、Gauß-Seidel方法和逐次超松弛方法，或Krylov子空间方法，如共轭梯度、广义最小残差或双共轭梯度。</p>
<h3 id="群">2.2 群</h3>
<blockquote>
<p>群的概念，它包含一组元素和一个定义在这些元素上的操作，该操作可以保持集合的某些结构完整。</p>
</blockquote>
<ul>
<li>封闭性(Closure)</li>
<li>结合律(Associativity)</li>
<li>单位元(Neutral elemen)</li>
<li>逆元(Inverse element)</li>
</ul>
<p>群在计算机科学中扮演着重要的角色。除了为集合上的运算提供一个基本框架外，它们还被大量应用于密码学、编码理论和图形学。</p>
<p>如果可交换运算顺序，是阿贝尔群( Abelian
group）(<strong>个人注：很多时候交换律都不是必须的。</strong>)</p>
<blockquote>
<p>向量空间的定义太赞了，通过群的定义引出！</p>
</blockquote>
<h3 id="线性变换的定义">2.3 线性变换的定义</h3>
<p>保持<strong>向量空间结构不变</strong>需满足:</p>
<p><span class="math display">\[
\forall x, y \in V\ \forall \lambda, \psi \in \mathbb{R} : \Phi(\lambda
\mathbf{x} + \psi \mathbf{y}) = \lambda \Phi(\mathbf{x}) + \psi
\Phi(\mathbf{y}).
\]</span></p>
<p>我们可以把线性映射用矩阵(2.7.1节)表示。回想一下前面的内容：我们将向量集合用矩阵的列表示。<strong>在处理矩阵时，我们必须判断矩阵所表示的内容：是线性映射还是向量集合。</strong></p>
<p><strong>空间结构不变的定义</strong>：</p>
<blockquote>
<p>从几何角度理解线性变换保持空间结构不变，可以帮助直观掌握线性变换的本质。</p>
<p>1、线性变换几何视角的理解</p>
<p><strong>线性变换</strong> <span class="math inline">\(\Phi: V \to
W\)</span> 是一种映射，满足：</p>
<ul>
<li>加法保持：<span class="math inline">\(\Phi(\mathbf{x} + \mathbf{y})
= \Phi(\mathbf{x}) + \Phi(\mathbf{y})\)</span></li>
<li>数乘保持：<span class="math inline">\(\Phi(\lambda \mathbf{x}) =
\lambda \Phi(\mathbf{x})\)</span></li>
</ul>
<p>这意味着：</p>
<p>1）<strong>直线映射为直线</strong> 任何向量空间中的直线（即所有形如
<span class="math inline">\(\mathbf{v}_0 + t\mathbf{v}\)</span>
的点集，其中 <span class="math inline">\(t \in
\mathbb{R}\)</span>）经过线性变换后，仍然是直线（或退化成一点）。换句话说，线性变换不会把直线扭曲成曲线。（详见”向量空间中直线的定义.md“）</p>
<p>2）<strong>原点保持不变</strong> 由于 <span
class="math inline">\(\Phi(\mathbf{0}) =
\mathbf{0}\)</span>，线性变换一定把原点映射为原点。这保持了空间的“参考点”。</p>
<p>3）<strong>比例保持</strong> 对于任意标量 <span
class="math inline">\(\lambda\)</span>，线性变换保证拉伸或压缩比例保持。例如，<span
class="math inline">\(\mathbf{x}\)</span> 拉伸两倍后变为 <span
class="math inline">\(2\mathbf{x}\)</span>，变换后也是变换 <span
class="math inline">\(\Phi(\mathbf{x})\)</span> 的两倍：<span
class="math inline">\(\Phi(2\mathbf{x}) =
2\Phi(\mathbf{x})\)</span>。</p>
<p>4）<strong>平行保持</strong>
如果两条线在原空间平行，那么它们的像也平行（或者重合）。这是因为线性变换保持向量加法关系。</p>
<p>5）<strong>向量加法的几何含义保持</strong>
变换前后，向量的组合关系（比如三角形的顶点、平行四边形的形状）在变换后的空间里依然成立（尽管大小和方向可能改变）。</p>
<p>2、换句话说</p>
<p>线性变换是“刚性”变换的一个推广，它可以拉伸、压缩、旋转、反射空间，但不会产生弯曲或折叠，也不会“撕裂”空间结构。<strong>它保持了“直线”、“比例”、“原点”这些最基础的几何性质。</strong></p>
<p>3、举个例子</p>
<ul>
<li><strong>旋转</strong>
是线性变换，保持长度和角度（保持空间结构不变的同时还保持距离）。</li>
<li><strong>缩放</strong>（拉伸/压缩）也是线性变换，改变大小但不改变“直线性”和“比例”。</li>
<li><strong>投影</strong>
是线性变换，把三维空间映射到二维平面，保持直线的映射，但改变维度和形状。</li>
</ul>
</blockquote>
<h3 id="变换矩阵">2.4 变换矩阵</h3>
<p><strong>注意变换矩阵(transformation
matrix)的定义。</strong>使用变换矩阵将相对于<span
class="math inline">\(V\)</span>的有序基的坐标映射到相对于<span
class="math inline">\(W\)</span>中有序基的坐标。</p>
<p>后文提到，为了简化变换矩阵，通过基变换处理。</p>
<p>在矩阵和有限维向量空间之间的线性映射之间建立一个显式联系（<strong>重点是理解线性变换和矩阵之间的本质联系！</strong>）。</p>
<h3 id="相似矩阵">2.5 相似矩阵</h3>
<p>如果存在可逆矩阵 <span
class="math inline">\(\boldsymbol{P}\)</span>，使得 <span
class="math display">\[
\boldsymbol{D} = \boldsymbol{P}^{-1} \boldsymbol{A} \boldsymbol{P}
\]</span> 则称矩阵 <span class="math inline">\(\boldsymbol{A}\)</span>
与 <span class="math inline">\(\boldsymbol{D}\)</span>
是相似(Similarity)的（定义 2.22）。</p>
<h3 id="恒等映射">2.6 恒等映射</h3>
<p><span class="math inline">\(\mathrm{id}_V : V \to V,\ x \mapsto
x\)</span> 为 <span class="math inline">\(V\)</span>
中的恒等映射或单位自同构（<strong>详见文件：‘恒等映射的存在意义.md“</strong>）。</p>
<h3 id="基变换">2.7 基变换</h3>
<p>重要的作用：同一个点，在不同的基的不同坐标表示！变换矩阵相当于坐标的映射（不同基）。</p>
<p>在第四章中，我们将利用基变换的概念来寻找一个基，使得自同态的变换矩阵有一个特别简单的（对角）形式。在第十章降维中，我们将利用基变换研究一个数据压缩问题，即找到一个基并在这个基上投影数据从而压缩数据，同时最小化压缩损失。</p>
<h3 id="变量变换和基变换区别">2.8 变量变换和基变换区别</h3>
<blockquote>
<p><strong>要分清楚基变换和变量变换的区别！不要混淆；两者得出的变换矩阵是不同的。</strong></p>
<p><img src="/img3/机器学习的数学基础Part1/变换.png" alt="变换" style="zoom:50%;" /></p>
<p>1、变量变换</p>
<p>如果给定两个向量 <span class="math inline">\(\boldsymbol{b}_{1} =
[1,0]^{\top}, \ \boldsymbol{b}_{2} = [0,1]^{\top}\)</span>
作为单位正方形（图5.5中的蓝色区域）的边，则该正方形的面积为： <span
class="math display">\[
\left|\det\!\begin{bmatrix}
1 &amp; 0 \\
0 &amp; 1
\end{bmatrix}\right| = 1
\]</span></p>
<p>如果我们取一个平行四边形（图5.5中的橙色区域），它的边为 <span
class="math inline">\(\boldsymbol{c}_{1} = [-2,1]^{\top}, \
\boldsymbol{c}_{2} = [1,1]^{\top}\)</span>，
则它的面积是行列式（见第4.1节）的绝对值： <span class="math display">\[
\left|\det\!\begin{bmatrix}
-2 &amp; 1 \\
1 &amp; 1
\end{bmatrix}\right|
= |-3| = 3
\]</span></p>
<p>即它的面积正好是单位方形的三倍。我们可以通过一个将单位方形转换成另一个方形的映射来找到这个缩放因子。用线性代数的术语说，就是有效地执行从
<span class="math inline">\((\boldsymbol{b}_{1},
\boldsymbol{b}_{2})\)</span> 到 <span
class="math inline">\((\boldsymbol{c}_{1}, \boldsymbol{c}_{2})\)</span>
的变量变换。在我们的例子中，这个映射是线性的，且它的行列式的绝对值正好给出了我们要寻找的缩放因子。</p>
<p>因为<span
class="math inline">\(\boldsymbol{b}_{1},\boldsymbol{b}_{2}\)</span>是基，根据变换矩阵的定义，故<strong>变换矩阵</strong>是：
<span class="math display">\[
A =
\begin{bmatrix}
-2 &amp; 1 \\
1 &amp; 1
\end{bmatrix}
\]</span></p>
<p>2、基变换</p>
<p>为了开始使用线性代数的方法，我们首先确定 <span
class="math inline">\(\{\boldsymbol{b}_{1},
\boldsymbol{b}_{2}\}\)</span> 和 <span
class="math inline">\(\{\boldsymbol{c}_{1},
\boldsymbol{c}_{2}\}\)</span> 都是 <span
class="math inline">\(\mathbb{R}^2\)</span> 的基。我们要有效地执行的是从
<span class="math inline">\(\{\boldsymbol{b}_{1},
\boldsymbol{b}_{2}\}\)</span> 到 <span
class="math inline">\(\{\boldsymbol{c}_{1},
\boldsymbol{c}_{2}\}\)</span> 的基变换，就得寻找实现基变换的变换矩阵。
利用第2.7.2节的结果，我们确定了所需的<strong>基变换矩阵</strong>为：
<span class="math display">\[
\boldsymbol{J} =
\begin{bmatrix}
-2 &amp; 1 \\
1 &amp; 1
\end{bmatrix} \tag{5.62}
\]</span></p>
<p>它使得 <span class="math inline">\(\boldsymbol{J}\boldsymbol{b}_{1} =
\boldsymbol{c}_{1}, \quad
\boldsymbol{J}\boldsymbol{b}_{2} = \boldsymbol{c}_{2}\)</span>。 矩阵
<span class="math inline">\(\boldsymbol{J}\)</span> 的行列式的绝对值为：
<span class="math display">\[
\left|\det(\boldsymbol{J})\right| = 3,
\]</span> 这正是我们在寻找的缩放因子。也就是说， <span
class="math inline">\((\boldsymbol{c}_{1}, \boldsymbol{c}_{2})\)</span>
所张成的平行四边形的面积是 <span
class="math inline">\((\boldsymbol{b}_{1}, \boldsymbol{b}_{2})\)</span>
所张成面积的三倍。</p>
<p>把 <span class="math inline">\(\{\boldsymbol{b}_{1},
\boldsymbol{b}_{2}\}\)</span> 坐标变换成 <span
class="math inline">\(\{\boldsymbol{c}_{1},
\boldsymbol{c}_{2}\}\)</span> 的坐标，是左乘<span
class="math inline">\(\boldsymbol{J}^{-1}\)</span>；反向是左乘<span
class="math inline">\(\boldsymbol{J}\)</span>。</p>
</blockquote>
<h3 id="像与核">2.8 像与核</h3>
<p>“直观地说，核是被 <span class="math inline">\(\Phi\)</span>
映射到单位元 <span class="math inline">\(\mathbf{0}_W \in W\)</span>
上的一组向量 <span class="math inline">\(\mathbf{v} \in
V\)</span>。”</p>
<p>具体见原书图2.12</p>
<p><img src="/img3/机器学习的数学基础Part1/F2.12.png" alt="F2.12" style="zoom:50%;" /></p>
<h3 id="仿射空间">2.9 仿射空间</h3>
<p>在下面，我们将研究从原点偏移的空间，即不再是向量子空间的空间。此外，我们将简要讨论这些仿射空间之间类似线性映射的一些性质。</p>
<p><strong>备注</strong>：
在机器学习领域的文献中，线性和仿射之间的区别有时是不明确的，因此我们可以将线性空间/映射作为仿射空间/映射的参考。</p>
<h3 id="仿射映射">2.10 仿射映射</h3>
<p>仿射映射保持几何结构不变。它们还保留了尺寸比例和平行度。</p>
<p>全书的读书笔记（共7篇）如下：<br />
<a href="/2025/12/05/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%B8%80/" title="《机器学习的数学基础》（1&#x2F;7）">《机器学习的数学基础》读书笔记之一 ：导言</a><br />
<a href="/2025/10/29/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BA%8C/" title="《机器学习的数学基础》（2&#x2F;7）">《机器学习的数学基础》读书笔记之二 ：线性代数</a><br />
<a href="/2025/10/28/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%B8%89/" title="《机器学习的数学基础》（3&#x2F;7）">《机器学习的数学基础》读书笔记之三 ：解析几何</a><br />
<a href="/2025/10/27/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9B%9B/" title="《机器学习的数学基础》（4&#x2F;7）">《机器学习的数学基础》读书笔记之四 ：矩阵分解</a><br />
<a href="/2025/10/26/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BA%94/" title="《机器学习的数学基础》（5&#x2F;7）">《机器学习的数学基础》读书笔记之五 ：向量微积分</a><br />
<a href="/2025/10/25/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%85%AD/" title="《机器学习的数学基础》（6&#x2F;7）">《机器学习的数学基础》读书笔记之六 ：概率与分布</a><br />
<a href="/2025/10/24/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%B8%83/" title="《机器学习的数学基础》（7&#x2F;7）">《机器学习的数学基础》读书笔记之七 ：连续优化</a></p>

    </div>

    
    
    

    <footer class="post-footer">

        


          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/10/28/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%B8%89/" rel="prev" title="《机器学习的数学基础》（3/7）">
                  <i class="fa fa-chevron-left"></i> 《机器学习的数学基础》（3/7）
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/11/02/AI%E5%AD%A6%E4%B9%A0%E4%B9%A6%E7%B1%8D%E4%BB%8B%E7%BB%8D/" rel="next" title="AI学习书籍介绍">
                  AI学习书籍介绍 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Rayman.hung</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
